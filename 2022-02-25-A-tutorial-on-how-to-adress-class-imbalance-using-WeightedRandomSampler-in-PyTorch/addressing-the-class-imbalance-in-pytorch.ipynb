{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A Tutorial on How to Adress Class Imbalance using WeightedRandomSampler in PyTorch\n\nClass imbalance is a very common problem in real world datasets. For example, a medical diagnosis dataset may have large number samples corresponding to the healthy class and very few samples belonging to the disease class. Class imbalance is detrimental to performance of the model, and it can lead to a very poor generalization. There are many ways to address this issue. In this article, we will focus on sampling strategies which can be implemented very easily in PyTorch.\n\n# Imbalance Dataset\n\nFirst, create a dummy dataset with imbalance classes. In this dataset, 90% of samples belong to *class 0* and 10% belong to *class 1*. Then, we create a PyTorch [TensorDataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.TensorDataset) and [DataLoader](https://pytorch.org/docs/stable/data.html).","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n\n# create dummy dataset\nnum_samples = 1024\ndata = torch.randn(num_samples,10) # dummy data\nnum_high_freq_samples = int(num_samples * 0.9)\ntargets = [0] * num_high_freq_samples + [1] * (num_samples - num_high_freq_samples)\n\n## convert targets to LongTensor\ntargets = torch.LongTensor(targets)\n\n# Create DataSet and DataLoader\ndataset = TensorDataset(data,targets)\ndataloader = DataLoader(dataset,batch_size=128, num_workers=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:50:47.593748Z","iopub.execute_input":"2022-02-25T16:50:47.594896Z","iopub.status.idle":"2022-02-25T16:50:48.968253Z","shell.execute_reply.started":"2022-02-25T16:50:47.594786Z","shell.execute_reply":"2022-02-25T16:50:48.967494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, iterate through dataloader and plot the distribution of classes in each batch.","metadata":{}},{"cell_type":"code","source":"def plot_function(x1,x2):\n    width =0.3\n    fig = plt.figure()\n    ax = fig.add_axes([0,0,1,1])\n    plt.bar(np.arange(1, len(x1)+1), x1, width=width)\n    plt.bar(np.arange(1, len(x2)+1)+ width, x2, width=width)\n    ax.legend(labels=['Class 0', 'Class 1'])\n    plt.show()\n\nzeros = []\nones = []\nfor idx, (x,y) in enumerate(dataloader):\n    unique, counts = np.unique(y.numpy(), return_counts=True)\n    zeros.append(counts[0])\n    ones.append(counts[1])\n\nplot_function(zeros,ones)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:50:49.962415Z","iopub.execute_input":"2022-02-25T16:50:49.962697Z","iopub.status.idle":"2022-02-25T16:50:50.34578Z","shell.execute_reply.started":"2022-02-25T16:50:49.96267Z","shell.execute_reply":"2022-02-25T16:50:50.344663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe high imbalance in Fig. 1., where all mini-batches are dominated by class 0. As only 10% of samples belong to *class 1*, the model is less likely to see learn useful features from this class.\n\n# Oversampling with WeightedRandomSampler\n\nWe can address the issue of imbalance by [oversampling strategy](https://arxiv.org/pdf/1710.05381.pdf). In oversampling, the key idea is to maintain a balance between two classes by oversampling the minor class. With oversampling, each mini-batch will have nearly equal number of samples drawn from both classes. \n\nIn PyTorch, Oversampling can be easily implemented using [WeightedRandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.WeightedRandomSampler). `WeightedRandomSampler` internally draws samples from *Multinomial Distribution* with controlled parameters. These parameters are `weights` and `num_samples`. Here,`weights` corresponds to weight assigned to each class sample. To draw nearly equal number samples from both classes (or have an equal probability of being sampled), the minor class should be assigned a higher weight. Below is an example for how to calculate weights for each class. ","metadata":{}},{"cell_type":"code","source":"# count occurance of each class\nunique, counts = np.unique(targets, return_counts=True)\n\n# calcuate weight of each class\nclass_weights = [1.0/c for c in counts]\n\n# assign weight to each sample\nsample_weights = [class_weights[i] for i in targets]\n\n# Create WeightedRandomSampler\nsampler = WeightedRandomSampler(sample_weights, len(sample_weights))\n\n# assign sampler\ndataloader = DataLoader(dataset,batch_size=128, num_workers=1,sampler=sampler)\n\n# iterate through dataset and plot class distribution in each batch\nzeros = []\nones = []\nfor idx, (x,y) in enumerate(dataloader):\n    unique, counts = np.unique(y.numpy(), return_counts=True)\n    zeros.append(counts[0])\n    ones.append(counts[1])\n\nplot_function(zeros,ones)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T16:50:53.239163Z","iopub.execute_input":"2022-02-25T16:50:53.239448Z","iopub.status.idle":"2022-02-25T16:50:53.546783Z","shell.execute_reply.started":"2022-02-25T16:50:53.239419Z","shell.execute_reply":"2022-02-25T16:50:53.545997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After calculating the weight for each sample, we initialize the `WeightedRandomSampler` with these weightes and pass it to the `sampler` argument in the `DataLoader`. After iterating through the dataloader, we plot the distribution of classes in each batch. It can be observed in Fig. 2. that after oversampling with `WeightedRandomSampler`, each mini-batch now has nearly equal number of samples from both classes. It should help to learn important features from the minor class and improve generalization of the model.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}